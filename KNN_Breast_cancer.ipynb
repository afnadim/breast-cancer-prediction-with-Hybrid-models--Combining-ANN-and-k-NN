{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division # backward compatibility for python2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.special\n",
    "import operator\n",
    "import random\n",
    "#library for plotting arrays\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# A particularly interesting backend, provided by IPython, is the inline backend. \n",
    "# This is available only for the Jupyter Notebook and the Jupyter QtConsole. \n",
    "# It can be invoked as follows: %matplotlib inline\n",
    "# With this backend, the output of plotting commands is displayed inline \n",
    "# within frontends like the Jupyter notebook, directly below the code cell that produced it. \n",
    "# The resulting plots are inside this notebook, not an external window.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets to read\n",
    "# useing the dataset already processed earlier in this project\n",
    "data_file = \"breast_cancer_processed.csv\"\n",
    "class_index = 0 # on inspection of the csv file we see that the class appears in zero position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read and split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename, class_idx=class_index, split=0.8):\n",
    "    dataframe = pd.read_csv(filename)\n",
    "    #dataframe = dataframe.sample(len(dataframe))\n",
    "    instances = dataframe.values\n",
    "    \n",
    "\n",
    "    print (\"Class Index: \"+str(class_idx))\n",
    "    # divide data into label and feature sets.\n",
    "    X = instances[:,class_idx:len(dataframe)] # you may need to change these depending on which dataset you are use\n",
    "    Y = instances[:,class_idx] \n",
    "    \n",
    "   \n",
    "    X_train = [] # features for the train set\n",
    "    Y_train = [] # class labels for the train set\n",
    "    X_test = [] # features for the test set\n",
    "    Y_test = [] # class labels for the test set\n",
    "    \n",
    "    # the zip iterator is a neat construct in Python\n",
    "    # it lets you iterate over 2 arrays / lists structures \n",
    "    # importantly it iterates upto the length of the smallest structure of the two \n",
    "    # in our case X and Y will be of same length\n",
    "    for  x, y in zip(X, Y): \n",
    "        if random.random() < split: # Return the next random floating point number in the range [0.0, 1.0) and compare\n",
    "            X_train.append(x)\n",
    "            Y_train.append(y)\n",
    "        else:\n",
    "            X_test.append(x)\n",
    "            Y_test.append(y)       \n",
    "    print(\"train set size: \", len(X_train))       \n",
    "    print(\"test set size: \", len(X_test))\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define similarity matrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Within our class we now need code for each of the components of k-NN.\n",
    "#First, lets create a method that will measure the distance between two vectors.\n",
    "def euclidean(instance1, instance2):\n",
    "        '''\n",
    "        Calculates euclidean distance between two instances of data\n",
    "        instance1 will be a List of Float values\n",
    "        instance2 will be a List of Float values\n",
    "        length will be an Integer denoting the length of the Lists\n",
    "        '''\n",
    "        distance = 0\n",
    "        for val1, val2 in zip(instance1, instance2):            \n",
    "            distance += pow((val1 - val2), 2)\n",
    "        \n",
    "        distance = pow(distance, 1/2)\n",
    "             \n",
    "              \n",
    "        return 1 / (1+ distance)\n",
    "    \n",
    "\n",
    "def manhattan(instance1, instance2):\n",
    "        '''\n",
    "        Calculates manhattan distance between two instances of data\n",
    "        instance1 will be a List of Float values\n",
    "        instance2 will be a List of Float values\n",
    "        length will be an Integer denoting the length of the Lists\n",
    "        '''\n",
    "        distance = 0\n",
    "        for val1, val2 in zip(instance1, instance2):\n",
    "            distance += abs(val1 - val2)      \n",
    "              \n",
    "        return 1 / (1+ distance)\n",
    "    \n",
    "def dot_product(instance1, instance2):\n",
    "        '''\n",
    "        Calculates dot product between two instances \n",
    "        instance1 will be a List of Float values\n",
    "        instance2 will be a List of Float values\n",
    "        length will be an Integer denoting the length of the Lists\n",
    "        '''\n",
    "        return np.dot(instance1, instance2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define evaulation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Finally, we can test to see how many of the test instances we got correct\n",
    "    def accuracy(results):\n",
    "        correct = 0\n",
    "        for predict, target in results:\n",
    "            \n",
    "            if predict == target:\n",
    "                correct += 1\n",
    "        return (correct/float(len(results))) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bulid the KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kNN:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    X_train, Y_train : list\n",
    "    these consists of the training set feature values and associated class labels\n",
    "    k : int\n",
    "    specify the number of neighbours\n",
    "    sim : literal\n",
    "    specify the name of the similarity metric (e.g. manhattan, eucliedean)\n",
    "    weighted : Boolean\n",
    "    specify the voting strategy as weighted or not weighted by similarity values\n",
    "  \n",
    "    Attributes\n",
    "    -----------  \n",
    "    Results : list\n",
    "      Target and predicted class labels for the test data.    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, X_train, Y_train, k=3, sim=manhattan, weighted=False):\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        \n",
    "        if k <= len(self.X_train):\n",
    "            self.k = k # set the k value for neighbourhood size\n",
    "        else:\n",
    "            self.k = len(self.X_train) # to ensure the get_neighbours dont crash\n",
    "    \n",
    "        self.similarity = sim # specify a sim metric that has been pre-defined e.g. manhattan or euclidean\n",
    "        \n",
    "        self.weighted = weighted # boolean to choose between weighted / unweighted majority voting\n",
    "        \n",
    "        #store results from testing \n",
    "        self.results= []\n",
    "        \n",
    "    #With k-NN, we are interested in finding the k number of points with the greatest similarity \n",
    "    # to the the query or test instance.\n",
    "    def get_neighbours(self, test_instance):\n",
    "        '''\n",
    "        Locate most similar neighbours \n",
    "        X_train will be a containing features (Float) values (i.e. your training data)\n",
    "        Y_train will be the corresponding class labels for each instance in X_train\n",
    "        test_instance will be a List of Float values (i.e. a query instance)\n",
    "        '''\n",
    "        similarities = [] # collection to store the similarities to be computed\n",
    "\n",
    "        for train_instance, y in zip(self.X_train, self.Y_train): #for each member of the training set\n",
    "            sim = self.similarity(test_instance, train_instance) #calculate the similarity to the test instance\n",
    "            \n",
    "            similarities.append((y, sim)) #add the actual label of the example and the computed similarity to a collection \n",
    "        #print(distances)\n",
    "        similarities.sort(key = operator.itemgetter(1), reverse = True) #sort the collection by decreasing similarity\n",
    "        neighbours = [] # holds the k most similar neighbours\n",
    "        for x in range(self.k): #extract the k top indices of the collection for return\n",
    "            neighbours.append(similarities[x])\n",
    "\n",
    "        return neighbours\n",
    "\n",
    "    # given the neighbours make a prediction\n",
    "    # the boolean parameter when set to False will use unweighted majority voting; otherwise weighted majority voting\n",
    "    # weighting can be helpful to break any ties in voting\n",
    "    def predict(self, neighbours):\n",
    "        '''\n",
    "        Summarise a prediction based upon weighted neighbours calculation\n",
    "        '''\n",
    "        class_votes = {}\n",
    "        for x in range(len(neighbours)):\n",
    "            response = neighbours[x][0]\n",
    "            if response in class_votes:\n",
    "                class_votes[response] += (1-self.weighted) + (self.weighted * neighbours[x][1]) #if not weighted simply add 1\n",
    "                #class_votes[response] += [1, neighbours[x][1]][weighted == True] \n",
    "              \n",
    "            else:\n",
    "                class_votes[response] = (1-self.weighted) + (self.weighted * neighbours[x][1])\n",
    "                #class_votes[response] = [1, neighbours[x][1]][weighted == True] \n",
    "                \n",
    "        #print(class_votes)\n",
    "        sorted_votes = sorted(class_votes, key = lambda k: (class_votes[k], k), reverse = True)\n",
    "        #print(sorted_votes)\n",
    "        return sorted_votes[0]\n",
    "    \n",
    "    #iterate through all the test data to calculate accuracy\n",
    "    def test(self, X_test, Y_test):\n",
    "        self.results = [] # store the predictions returned by kNN\n",
    "\n",
    "        for test_instance, target_label in zip(X_test, Y_test):\n",
    "            neighbours = self.get_neighbours(test_instance)\n",
    "            predict_label = self.predict(neighbours)\n",
    "            self.results.append([predict_label, target_label])\n",
    "            #print('> predicted = ', result,', actual = ', test_label)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalise the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input=(np.asfarray(X_train[:-1])/255)*0.99+0.01\n",
    "#X_train=input\n",
    "#input=(np.asfarray(X_test[:-1])/255)*0.99+0.01\n",
    "#X_test=input\n",
    "#input=(np.asfarray(Y_train[:-1])/255)*0.99+0.01\n",
    "#Y_train=input\n",
    "#input=(np.asfarray(Y_test[:-1])/255)*0.99+0.01\n",
    "#Y_test=input\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Index: 0\n",
      "train set size:  458\n",
      "test set size:  110\n"
     ]
    }
   ],
   "source": [
    "#Load the dataset and maintain the features (X) and class labels (Y) separately  \n",
    "# make sure you understand what the 4 and 0.8 default values are in the call\n",
    "# you may have to modify these depending on the dataset you work with.\n",
    "X_train, Y_train, X_test, Y_test = load_dataset(data_file, 0, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply kNN to test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN Accuracy on test set is:  90.0\n"
     ]
    }
   ],
   "source": [
    "#create an instance of kNN \n",
    "# pass the training instances with their class labels (i.e. X_train and Y_train)\n",
    "# we will use the default kNN class settings for parameters i.e. k=3, sim=manhattan, weighted=False\n",
    "\n",
    "knn = kNN(X_train, Y_train)\n",
    "knn.test(X_test, Y_test) # now get the predictions on the test set\n",
    "\n",
    "print(\"kNN Accuracy on test set is: \", accuracy(knn.results))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN with multiple values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Index: 0\n",
      "train set size:  454\n",
      "test set size:  114\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = load_dataset(data_file, 0, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup the kNN instances ...\n",
      "Results from trials... [[85.96491228070175, 93.85964912280701, 92.98245614035088, 92.10526315789474, 92.98245614035088], [85.96491228070175, 92.98245614035088, 92.10526315789474, 92.98245614035088, 92.10526315789474]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Setup the kNN instances ...\")\n",
    "knn_list = []\n",
    "ks = [1, 10, 20, 30, 40] # try a few different values for k\n",
    "is_weighted = [False, True] # try two different forms of voting\n",
    "\n",
    "# iterate over different voting strategies\n",
    "for weighted in is_weighted:\n",
    "    knn_list_element = [] # first set of knns with a specified voting scheme\n",
    "    #iterate over different k values\n",
    "    for k in ks:\n",
    "        #create the different instances of the kNN class\n",
    "        knn = kNN(X_train, Y_train, k, euclidean, weighted)\n",
    "        \n",
    "        knn_list_element.append(knn)\n",
    "        pass\n",
    "    \n",
    "    knn_list.append(knn_list_element)# now append the set of models \n",
    "    pass\n",
    "\n",
    "\n",
    "#lets test the kNNs \n",
    "#iterate through each model and accumilate number of correct predictions\n",
    "knn_results = []\n",
    "knn_result_element = []\n",
    "\n",
    "for knn1 in knn_list:\n",
    "    knn_result_element = []\n",
    "\n",
    "    for knn2 in knn1:\n",
    "        knn2.test(X_test, Y_test)\n",
    "             \n",
    "        knn_result_element.append(accuracy(knn2.results))\n",
    "        \n",
    "        pass\n",
    "    pass\n",
    "    knn_results.append(knn_result_element)\n",
    "    pass\n",
    "print(\"Results from trials...\", knn_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = len(ks) # this is the number of results we want to plot pn the x-axis\n",
    "ind = np.arange(N) \n",
    "\n",
    "performance1 = knn_results[0]\n",
    "performance2 = knn_results[1]\n",
    "\n",
    "width = 0.35 # width of the bar      \n",
    "plt.bar(ind, performance1, width, label='Unweighted')\n",
    "plt.bar(ind + width, performance2, width, label='Weighted')\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('k')\n",
    "plt.title('kNN performance(Breast Cancer Dataset)')\n",
    "\n",
    "plt.xticks(ind + width / 2, ks)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
